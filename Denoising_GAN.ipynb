{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vebrahimi1990/GAN-in-Colab/blob/main/Denoising_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Denoinsg Super-Resolution Images with GAN**\n",
        "\n",
        "This is a short tutorial on how to use GAN (Generative Adversarial Network) for image denoising. In this tutorial you will learn how to upload your data set in Google Colab and use it to train a GAN and later test it on your test data set.\n",
        "\n",
        "To use this notebook, first, you need to set up a google drive account for yourself. It is very easy; in case you already have a google account. Just click on this link (https://drive.google.com/drive/my-drive ) and sign in with your Google username and password. \n",
        "\n",
        "After creating your Google drive, it is time to create a folder to copy your data set in it. This is a very crucial part of using our Colab Notebook. For denoising you need to have two pairs of data. One pair is the noisy (low SNR) image, and the other is your ground truth (high SNR) image from the same area (FOV). Please, make sure that each pair has the same name as it is shown here:\n",
        "\n",
        "    (Folder) dataset\n",
        "      (Folder) train data \n",
        "        (Folder)Low SNR: 1.tif, 2.tif, 3.tif, …\n",
        "        (Folder)GT: 1.tif, 2.tif, 3.tif, …\n",
        "    (Folder) test data \n",
        "        (Folder)Low SNR: 1.tif, 2.tif, 3.tif, …\n",
        "        (Folder)GT: 1.tif, 2.tif, 3.tif, …\n",
        "For instance, 1.tif in Low SNR folder and GT folder should show the same area. This needs to be done to make it easier to import the data in the Colab Notebook. It is always better to provide more data for training a deep learning network, however, there is a trade-off between the size of the dataset and the training time. We suggest the training set contains at least 15 images and each image shows an area of 20 micron*20micron. \n",
        "\n",
        "After preparing the folder containing all the training and test data, you can simply drag and drop it in your Google drive. \n",
        "\n",
        "The next step is to make sure that you have mounted your Google Drive in the Colab Notebook. To do that simply click on the Folder icon on the left side of this screen and push the button **Mount Drive**. \n",
        "\n",
        "Before start to use our Notebook, there is another crucial step. You need to make sure you have access to a GPU to accelerate training our model. Training deep learning networks with CUP can be very slow. To use GPU, simply click on **Runtime** menu at the top of this screen, click on **Change runtime type** and choose **GPU** as your hardware accelerator, then click on the save button and wait for a few seconds until a GPU is allocated to you. \n",
        "\n",
        "At this point you should be able to start using the Notebook. A Collab Notebook consists of multiple blocks which are called cells. Each cell contains a piece of code. There is play button at the top left of each cell and by pushing that button you can run the cell. There is a short description at the top of each cell which tells you why you need to run that cell. Now, please start playing with this Notebook and enjoy the power of deep learning for your denoising application.\n",
        "\n",
        "**Good luck!**\n"
      ],
      "metadata": {
        "id": "S-2Gt6BHSHnu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cell #1**\n",
        "\n",
        "Please, run this cell to import all the necessary tools for building our deep learning network. These tools are used in the following blocks, therefore, they need to be imported first. "
      ],
      "metadata": {
        "id": "WVpLnKzVcVGr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tv4sbUfUXbVa",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Importing the necessary libraries  { form-width: \"50%\" }\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout,LayerNormalization, Flatten, LeakyReLU, ReLU\n",
        "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
        "from keras.layers.merge import concatenate, add\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from skimage.io import imread\n",
        "import time\n",
        "from IPython import display\n",
        "from tifffile import imsave"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cell #2**\n",
        "This is a quick test to make sure we have access to a GPU. If you get an error please go back to the Runtime and make sure you choose GPU as your accelerator. "
      ],
      "metadata": {
        "id": "uFKvLHxQcu2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Make sure you have access to a GPU { form-width: \"50%\" }\n",
        "assert len(tf.config.list_physical_devices('GPU')) > 0"
      ],
      "metadata": {
        "id": "7ejamwGmPR5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cell #3**\n",
        "\n",
        "Now, it is time to import your training set to the Colab Notebook. To do so, please copy and past your training file path in front of **image_dr:** such as:\n",
        "\n",
        " /**content/drive/My Drive/**dataset/training\n",
        "\n",
        " After running the cell you should be able to see the names of your images in your training set. \n",
        "\n",
        " There are a few parameters that need to be set in this cell. First, please import your image size. This number shows how many pixels are in your original dataset. For instance, 1024 means that your images are 1024*1024. \n",
        "\n",
        "The next parameter is patch_size. When we train a deep learning network for denoising, we need to creat smaller patches from our large size training data. This is because we can enlarge our dataset and prevent memory overflowing. a patch size of 128 is a reasonable number but you can change it to bigger or smaller. Also, it is better that the number be a power of 2. \n",
        "\n",
        "The last parameter in this cell is the number of patches that we want to creat from each image. This number should be chosen based on the size of your original image size and it should be 4,16,64,256,... ."
      ],
      "metadata": {
        "id": "KwinZh-gc_gb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Directory to the training set { form-width: \"50%\" }\n",
        "image_dr = \"/content/drive/My Drive/data/Fast_STED_Confocal_vs_STED/STED\" #@param {type:\"string\"}\n",
        "image_size = 1024 #@param {type:\"integer\"}\n",
        "image_list = os.listdir(image_dr+\"/Average\")\n",
        "print('The image file names are:', *image_list,sep='\\n')\n",
        "M = len(image_list)\n",
        "GT = np.empty((M,1024,1024,1),dtype=np.float32)\n",
        "low = np.empty((M,1024,1024,1),dtype=np.float32)\n",
        "\n",
        "for i in range(M):\n",
        "  img_GT = load_img(image_dr + \"/Average/\"+image_list[i], color_mode=\"grayscale\")\n",
        "  img_low = load_img(image_dr + \"/1frame/\"+image_list[i], color_mode=\"grayscale\")\n",
        "\n",
        "  GT[i] = img_to_array(img_GT).astype(np.float32)\n",
        "  low[i] = img_to_array(img_low).astype(np.float32)\n",
        "\n",
        "patch_size = 64 #@param {type:\"integer\"}\n",
        "n_patches_per_image =  16#@param {type:\"integer\"}\n",
        "n_patches_per_row   = np.sqrt(n_patches_per_image)\n",
        "n_patches_per_row = int(n_patches_per_row)\n",
        "\n",
        "rr = np.floor(np.linspace(0,image_size-patch_size-1,n_patches_per_row))\n",
        "rr.astype(int)\n",
        "cc = rr\n",
        "\n",
        "xx = np.empty((M*n_patches_per_image,patch_size,patch_size,1),dtype=np.float32)\n",
        "yy = np.empty((M*n_patches_per_image,patch_size,patch_size,1),dtype=np.float32)\n",
        "\n",
        "X = np.empty((4*M*n_patches_per_image,patch_size,patch_size,1),dtype=np.float32)\n",
        "Y = np.empty((4*M*n_patches_per_image,patch_size,patch_size,1),dtype=np.float32)\n",
        "\n",
        "count = 0\n",
        "for i in range(M):\n",
        "  for j in range(n_patches_per_row):\n",
        "    for k in range(n_patches_per_row):\n",
        "      xx[count] = low[i,j:j+patch_size,k:k+patch_size,:]\n",
        "      xx[count] = xx[count]/xx[count].max()\n",
        "      yy[count] = GT[i,j:j+patch_size,k:k+patch_size,:]\n",
        "      yy[count] = yy[count]/yy[count].max()\n",
        "      count+=1\n",
        "\n",
        "X[0:count,:,:,:]=xx\n",
        "X[count:2*count,:,:,:]=np.flip(xx,axis=1)\n",
        "X[2*count:3*count,:,:,:]=np.flip(xx,axis=2)\n",
        "X[3*count:4*count,:,:,:]=np.flip(xx,axis=(1,2))\n",
        "\n",
        "Y[0:count,:,:,:]=yy\n",
        "Y[count:2*count,:,:,:]=np.flip(yy,axis=1)\n",
        "Y[2*count:3*count,:,:,:]=np.flip(yy,axis=2)\n",
        "Y[3*count:4*count,:,:,:]=np.flip(yy,axis=(1,2))\n",
        "\n",
        "\n",
        "aa = np.linspace(0,len(X)-1,len(X))\n",
        "random.shuffle(aa)\n",
        "aa = aa.astype(int)\n",
        "\n",
        "XX = np.empty((4*M*n_patches_per_image,patch_size,patch_size,1),dtype=np.float32)\n",
        "YY = np.empty((4*M*n_patches_per_image,patch_size,patch_size,1),dtype=np.float32)\n",
        "\n",
        "for i in range(len(X)):\n",
        "  XX[i,:,:,:] = X[aa[i],:,:,:]\n",
        "  YY[i,:,:,:] = Y[aa[i],:,:,:]\n",
        "\n",
        "# Split train and valid\n",
        "ratio = 0.8\n",
        "M1 = np.floor(X.shape[0]*ratio).astype(np.int32)\n",
        "X_train = XX[0:M1,:,:,:]\n",
        "Y_train = YY[0:M1,:,:,:]\n",
        "X_valid = XX[M1::,:,:,:]\n",
        "Y_valid = YY[M1::,:,:,:]\n",
        "\n",
        "print('The training set shape is:',X_train.shape)\n",
        "print('The validation set shape is:',X_valid.shape)"
      ],
      "metadata": {
        "id": "kp_fudHmSiXl",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cell #4**\n",
        "\n",
        "You can randomly see pair of your dataset by running this cell. "
      ],
      "metadata": {
        "id": "WgnXD94jhDNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot pairs of images in your dataset { form-width: \"50%\" }\n",
        "variable_name = \"a\"\n",
        "ix = random.randint(0, len(X))\n",
        "fig = plt.figure(figsize=(15,15))\n",
        "fig.add_subplot(1,2, 1)\n",
        "cmap=plt.get_cmap('magma')\n",
        "plt.imshow(X[ix].squeeze(),cmap)\n",
        "plt.axis('off')\n",
        "\n",
        "fig.add_subplot(1,2, 2)\n",
        "cmap=plt.get_cmap('magma')\n",
        "plt.imshow(Y[ix].squeeze(),cmap)\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "CjIkQV8cKQ5a",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cell #5**\n",
        "\n",
        "Please, specifiy the number of the convolutional filters, number of the layers, and the learning rate of your network. You can also use the preset parameters. Increasing the number of filters or the number of layers can add to the prediction accuracy, but there is always a trade-off between the size of a network and the GPU memory. Finding the optimal learning rate is very tricky, so you can just use the pre-set learning rate. A very small learning rate can make learning learning process slow, while a large learning rate can lead to learning instability. \n",
        "\n",
        "After running this cell, you should be able to see a plot of your generator model. "
      ],
      "metadata": {
        "id": "zxioY-D0meko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define the hyperparameters of your model { form-width: \"50%\" }\n",
        "num_filters = 16 #@param {type:\"integer\"}\n",
        "num_layers =  2#@param {type:\"integer\"}\n",
        "learning_rate =  5e-5#@param {type:\"number\"}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet',input_tensor=Input(shape=(patch_size, patch_size, 3)))\n",
        "inter_vgg1 = Model(inputs = vgg.input, outputs=vgg.get_layer(vgg.layers[1].name).output)\n",
        "inter_vgg2 = Model(inputs = vgg.input, outputs=vgg.get_layer(vgg.layers[2].name).output)\n",
        "inter_vgg4 = Model(inputs = vgg.input, outputs=vgg.get_layer(vgg.layers[4].name).output)\n",
        "inter_vgg5 = Model(inputs = vgg.input, outputs=vgg.get_layer(vgg.layers[5].name).output)\n",
        "inter_vgg7 = Model(inputs = vgg.input, outputs=vgg.get_layer(vgg.layers[7].name).output)\n",
        "inter_vgg8 = Model(inputs = vgg.input, outputs=vgg.get_layer(vgg.layers[8].name).output)\n",
        "inter_vgg12 = Model(inputs = vgg.input, outputs=vgg.get_layer(vgg.layers[12].name).output)\n",
        "inter_vgg17 = Model(inputs = vgg.input, outputs=vgg.get_layer(vgg.layers[17].name).output)\n",
        "inter_vgg = [inter_vgg1,inter_vgg2,inter_vgg4,inter_vgg5,inter_vgg7,inter_vgg8,inter_vgg12,inter_vgg17]\n",
        "\n",
        "def nmse_loss(pred,gt):\n",
        "  mse = tf.keras.metrics.mean_squared_error(pred,gt)\n",
        "  mse = tf.math.reduce_sum(mse,axis=(1,2))\n",
        "  norm = tf.norm(gt,axis=(1,2))\n",
        "  norm = tf.squeeze(norm)\n",
        "  norm = tf.pow(norm,2)\n",
        "  norm = tf.math.reduce_sum(norm)\n",
        "  nmse = tf.math.divide(mse,norm)\n",
        "  nmse = tf.math.reduce_mean(nmse)\n",
        "  return nmse\n",
        "\n",
        "def fft_loss(pred,gt):\n",
        "  pred = tf.transpose(pred, perm=[0, 3, 1, 2])\n",
        "  gt   = tf.transpose(gt, perm=[0, 3, 1, 2])\n",
        "\n",
        "  pred_fft = tf.signal.fftshift(tf.signal.rfft2d(pred))\n",
        "  gt_fft   = tf.signal.fftshift(tf.signal.rfft2d(gt))\n",
        "\n",
        "  pred_fft = tf.transpose(pred_fft, perm=[0, 2, 3, 1])\n",
        "  gt_fft   = tf.transpose(gt_fft, perm=[0, 2, 3, 1])\n",
        "\n",
        "  ft_loss = nmse_loss(pred_fft,gt_fft)\n",
        "  ft_loss = tf.cast(ft_loss,tf.float32)\n",
        "  return ft_loss\n",
        "\n",
        "\n",
        "def percep_loss(pred,gt):\n",
        "  ploss = 0\n",
        "  nmse = nmse_loss(pred,gt)\n",
        "  ft_loss = fft_loss(pred,gt)\n",
        "  ssim_loss = 1.0-tf.math.reduce_mean(tf.image.ssim(pred,gt,max_val=1))\n",
        "  pred = tf.image.grayscale_to_rgb(pred)\n",
        "  gt   = tf.image.grayscale_to_rgb(gt)\n",
        "  for i in range(8):\n",
        "    vgg_pred = inter_vgg[i](pred)\n",
        "    vgg_gt = inter_vgg[i](gt)\n",
        "    ploss = ploss+nmse_loss(vgg_pred,vgg_gt)\n",
        "  ploss = 1000*(ploss)+0.1*ssim_loss+5*nmse+20*ft_loss\n",
        "  return ploss\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = -tf.math.log(real_output)\n",
        "    fake_loss = -tf.math.log(1.0-fake_output+tf.math.sign(fake_output-0.5)*1e-8)\n",
        "    total_loss = tf.math.reduce_mean(real_loss + fake_loss)\n",
        "    return total_loss\n",
        "\n",
        "def generator_validation_loss(pred,gt):\n",
        "  ssim_loss = 1.0-tf.math.reduce_mean(tf.image.ssim(pred,gt,max_val=1))\n",
        "  nmse = nmse_loss(pred,gt)\n",
        "  valid_loss = ssim_loss+1e-3*nmse\n",
        "  return valid_loss\n",
        "\n",
        "\n",
        "def dis_conv_block(inpt,num_filters=64,kernel_shape=(3,3),strides=(1,1)):\n",
        "  x = Conv2D(num_filters, kernel_shape, padding=\"same\",strides=strides)(inpt)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU()(x)\n",
        "  return x\n",
        "\n",
        "def res_conv_block(inputs,num_filters=32,kernel_shape=(3,3)):\n",
        "  x = Conv2D(num_filters, kernel_shape, padding=\"same\")(inputs)\n",
        "  x = BatchNormalization()(x,training=False)\n",
        "  x = LeakyReLU()(x)\n",
        "  x = Conv2D(num_filters, kernel_shape, padding=\"same\")(x)\n",
        "  x = BatchNormalization()(x,training=False)\n",
        "  x = add([x,inputs])\n",
        "  return x\n",
        "\n",
        "def conv_block(inputs,num_filters=32,kernel_shape=(3,3)):\n",
        "  x = Conv2D(num_filters, kernel_shape, padding=\"same\")(inputs)\n",
        "  x = BatchNormalization()(x,training=False)\n",
        "  x = LeakyReLU()(x)\n",
        "  x = Conv2D(num_filters, kernel_shape, padding=\"same\")(x)\n",
        "  x = BatchNormalization()(x,training=False)\n",
        "  return x\n",
        "\n",
        "def make_discriminator(input_gen,input_gt,num_filters=num_filters,kernel_shape=(3,3)):\n",
        "  x = concatenate([input_gen,input_gt])\n",
        "  x = Conv2D(num_filters, kernel_shape, padding=\"same\")(x)\n",
        "  x = LeakyReLU()(x)\n",
        "  x = dis_conv_block(x,num_filters,kernel_shape,strides=(2,2))\n",
        "  x = dis_conv_block(x,2*num_filters,kernel_shape,strides=(1,1))\n",
        "  x = dis_conv_block(x,2*num_filters,kernel_shape,strides=(2,2))\n",
        "  x = dis_conv_block(x,4*num_filters,kernel_shape,strides=(1,1))\n",
        "  x = dis_conv_block(x,4*num_filters,kernel_shape,strides=(2,2))\n",
        "  x = dis_conv_block(x,8*num_filters,kernel_shape,strides=(1,1))\n",
        "  x = dis_conv_block(x,8*num_filters,kernel_shape,strides=(2,2))\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(256)(x)\n",
        "  x = LeakyReLU()(x)\n",
        "  x = Dense(1)(x)\n",
        "  x = Activation(\"sigmoid\")(x)\n",
        "  model = Model(inputs=[input_gen,input_gt], outputs=[x])\n",
        "  return model\n",
        "\n",
        "def make_generator(inputs,num_filters=num_filters,num_layers=num_layers,kernel_shape=(3,3),dropout=0.4):\n",
        "  filters = []\n",
        "  skip_x = []\n",
        "  for i in range(num_layers):\n",
        "    filters.append((2**i)*num_filters)\n",
        "  y = Conv2D(num_filters,kernel_shape, padding = 'same')(inputs)\n",
        "  y = LeakyReLU()(y)\n",
        "  x = y\n",
        "  for f in filters:\n",
        "    x = res_conv_block(x, f,kernel_shape)\n",
        "    skip_x.append(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Dropout(dropout)(x,training=False)\n",
        "    x = Conv2D(2*f,kernel_shape, padding = 'same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU()(x)\n",
        "\n",
        "  x = res_conv_block(x, 2*filters[-1],kernel_shape)\n",
        "  filters.reverse()\n",
        "  skip_x.reverse()\n",
        "\n",
        "  for i, f in enumerate(filters):\n",
        "    x = Conv2DTranspose(f,kernel_shape, strides = (2, 2), padding = 'same')(x)\n",
        "    xs = skip_x[i]\n",
        "    x = concatenate([x, xs])\n",
        "    x = LeakyReLU()(x)\n",
        "    x = Dropout(dropout)(x,training=False)\n",
        "    x = conv_block(x, f,kernel_shape)\n",
        "\n",
        "  x = Conv2D(num_filters, kernel_shape, padding=\"same\")(x)\n",
        "  x = LeakyReLU()(x)\n",
        "  x = add([x,y])\n",
        "  x = Conv2D(num_filters, kernel_shape, padding=\"same\")(x)\n",
        "  x = LeakyReLU()(x)\n",
        "  x = Conv2D(1, kernel_shape, padding=\"same\")(x)\n",
        "  model = Model(inputs=[inputs], outputs=[x])\n",
        "  return model\n",
        "\n",
        "def make_gan(generator,discriminator,inputs):\n",
        "  gen_out = generator(inputs)\n",
        "  dis_out = discriminator([gen_out,inputs])\n",
        "  model = Model(inputs=inputs,outputs=[dis_out,gen_out])\n",
        "  return model\n",
        "\n",
        "gan_lr = learning_rate\n",
        "dis_opt = keras.optimizers.Adam(learning_rate=gan_lr)\n",
        "gan_opt = keras.optimizers.Adam(learning_rate=gan_lr)\n",
        "\n",
        "discrim_input = Input((patch_size,patch_size,1))\n",
        "discrim_input1 = Input((patch_size,patch_size,1))\n",
        "gen_input = Input((patch_size,patch_size,1))\n",
        "gan_input = Input((patch_size,patch_size,1))\n",
        "\n",
        "dis_model = make_discriminator(discrim_input,discrim_input1,num_filters=64)\n",
        "gen_model = make_generator(gen_input,num_filters=num_filters,num_layers=num_layers,kernel_shape=(3,3),dropout=0.3)\n",
        "gan_model = make_gan(gen_model,dis_model,gan_input)\n",
        "\n",
        "dis_model.compile(optimizer=dis_opt,loss=['binary_crossentropy'], loss_weights=[1])\n",
        "gan_model.compile(optimizer=gan_opt,loss=['binary_crossentropy',percep_loss],loss_weights=[0.01,1])\n",
        "gen_model.compile(optimizer=gan_opt,loss=percep_loss)\n",
        "\n",
        "#gan_model.summary()\n",
        "#gen_model.summary()\n",
        "#dis_model.summary()\n",
        "tf.keras.utils.plot_model(gen_model,show_shapes=True, show_layer_names=True, dpi=40)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "J-sFSmL6lqV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cell #6**\n",
        "\n",
        "In this cell, you can train your network with your provided training dataset. To do so, first specify two separate directories in your Google Drive for saving your model weights and also your loss values. The extension for saving the model weights and loss values should be **.h5** and **.csv**, respectively. Then you can specifiy the number of epochs and the number of batches. The number of epochs means how many iterations you want to train your network. The number of batches determine how many images from your training set should be used at each iteration within an epoch. For instance if you have 1024 images in your training set and you choose your batch size 64, then your network goes through 16 iterations within each epoch. \n",
        "\n",
        "By pushing the play button your network starts the training process. After each epoch, it eveluates the network on a validation data-set and if the validation loss decreases, the model weights will be saved. "
      ],
      "metadata": {
        "id": "7NMWMs4jBjL6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d2Xe1vBN_r_",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Training loop parameters { form-width: \"50%\" }\n",
        "model_save_directory = \"/content/drive/My Drive/model-GAN.h5\" #@param {type:\"string\"}\n",
        "loss_save_directory = \"/content/drive/My Drive/model-GAN-loss.csv\" #@param {type:\"string\"}\n",
        "n_epochs = 100 #@param {type:\"integer\"}\n",
        "n_batch =  32#@param {type:\"integer\"}\n",
        "def generate_real_samples(low,gt,batch_size):\n",
        "\tix = np.random.randint(0, low.shape[0]-batch_size, batch_size)\n",
        "\tX1, X2 = low[ix],gt[ix]\n",
        "\ty = np.ones((batch_size, 1))\n",
        "\treturn [X1, X2], y\n",
        "\n",
        "def generate_fake_samples(X1,gen_model,batch_size):\n",
        "  X = gen_model.predict(X1)\n",
        "  y = np.zeros((batch_size, 1))\n",
        "  return X, y\n",
        "\n",
        "def train(dis_model, gen_model, gan_model,low,gt,low_valid,gt_valid, n_epochs=100, n_batch=32):\n",
        "  n_steps = np.floor(low.shape[0]/n_batch).astype(np.int32)\n",
        "  loss = np.zeros((n_epochs,4))\n",
        "  lossv = np.zeros((n_epochs,1))\n",
        "  count = 0\n",
        "  for m in range(n_epochs):\n",
        "    start = time.time()\n",
        "    dis_loss1 = 0\n",
        "    dis_loss2 = 0\n",
        "    gan_loss  = 0\n",
        "    val_loss  = 0\n",
        "    for j in range(n_steps):\n",
        "      [X1, X2], y_real = generate_real_samples(low,gt,n_batch)\n",
        "      [X1_valid, X2_valid], y_real_valid = generate_real_samples(low_valid,gt_valid,n_batch)\n",
        "      X_fakeB, y_fake = generate_fake_samples(X1,gen_model,n_batch)\n",
        "      dis_loss1 = dis_model.train_on_batch([X1, X2], y_real) +dis_loss1\n",
        "      dis_loss2 = dis_model.train_on_batch([X1, X_fakeB], y_fake) + dis_loss2\n",
        "      gan_loss1,_,_  = gan_model.train_on_batch(X1,[y_real,X2])\n",
        "      gan_loss = gan_loss1 + gan_loss\n",
        "      val_loss1 = gen_model.test_on_batch(X1_valid,X2_valid)\n",
        "      val_loss = val_loss1 + val_loss\n",
        "    val_loss = val_loss/n_steps\n",
        "    gan_loss = gan_loss/n_steps\n",
        "    dis_loss1 = dis_loss1/n_steps\n",
        "    dis_loss2 = dis_loss2/n_steps\n",
        "\n",
        "\n",
        "\n",
        "    loss[m,0] = dis_loss1\n",
        "    loss[m,1] = dis_loss2\n",
        "    loss[m,2] = gan_loss \n",
        "    loss[m,3] = val_loss\n",
        "    lossv[m,0] = val_loss\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "\n",
        "    current_lr = tf.keras.backend.eval(gan_model.optimizer.lr)\n",
        "    print('learning rate:',current_lr)\n",
        "    if np.remainder(count+1,10) == 0:\n",
        "      if current_lr>1e-7:\n",
        "        update_lr  = current_lr*0.5\n",
        "        tf.keras.backend.set_value(gan_model.optimizer.learning_rate,update_lr)\n",
        "        tf.keras.backend.set_value(dis_model.optimizer.learning_rate,update_lr)\n",
        "\n",
        "    if m==0:\n",
        "      gen_model.save_weights(model_save_directory,overwrite=True)\n",
        "    else:\n",
        "      if val_loss <= np.min(lossv[np.nonzero(lossv)]):\n",
        "        gen_model.save_weights(model_save_directory,overwrite=True)\n",
        "        print('model is saved')\n",
        "        count = 0\n",
        "      else:\n",
        "        count = count + 1\n",
        "    if count==100:\n",
        "      print('Training is stopped')\n",
        "      break \n",
        "    \n",
        "    np.savetxt(loss_save_directory, loss, delimiter=\",\")\n",
        "\n",
        "\n",
        "    \n",
        "    print('>%d, d1[%.3f] d2[%.3f] g[%.3f] val[%3f]' % (m+1, dis_loss1, dis_loss2, gan_loss, val_loss))\n",
        "    print ('Time for epoch {} is {} sec'.format(m + 1, time.time()-start))\n",
        "    ix = 4\n",
        "    predictions = gen_model.predict(X_valid[ix:ix+1])\n",
        "    fig = plt.figure(figsize = (20,15))\n",
        "    for i in range(predictions.shape[0]):\n",
        "      plt.subplot(1, 3, 3*i+1)\n",
        "      plt.imshow(X_valid[i+ix, :, :, 0] , cmap='magma')\n",
        "      plt.axis('off')\n",
        "      plt.subplot(1, 3, 3*i+2)\n",
        "      plt.imshow(predictions[i, :, :, 0] , cmap='magma')\n",
        "      plt.axis('off')\n",
        "      plt.subplot(1, 3, 3*i+3)\n",
        "      plt.imshow(Y_valid[i+ix, :, :, 0] , cmap='magma')\n",
        "      plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "  return loss\n",
        "\n",
        "loss = train(dis_model,gen_model,gan_model,X_train,Y_train,X_valid,Y_valid,n_epochs = n_epochs, n_batch=n_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cell #7**\n",
        " \n",
        " Here, we can plot our training and validation losses and see if our network is still need to be trained for more epochs or not. You can choose to plot the loss values between **epoch#1** and **epoch#2**. "
      ],
      "metadata": {
        "id": "hj_nYAtU4_0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot training and validation losses { form-width: \"50%\" }\n",
        "epoch1 = 40 #@param {type:\"integer\"}\n",
        "epoch2 = 100 #@param {type:\"integer\"}\n",
        "loss_value_directory = \"/content/drive/My Drive/model-GAN-loss.csv\" #@param {type:\"string\"}\n",
        "\n",
        "loss_file = open(loss_value_directory)\n",
        "ll = np. loadtxt(loss_file, delimiter=\",\")\n",
        "mm = np.linspace(epoch1,epoch2,epoch2-epoch1)\n",
        "plt.plot(mm,ll[epoch1:epoch2,2],mm,ll[epoch1:epoch2,3])\n",
        "plt.legend(['training loss','validation loss'])"
      ],
      "metadata": {
        "id": "yw-SKNA_xtsw",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cell #8**\n",
        "\n",
        "Now, it is time to have fun and see the results of your trained network. To do so, first you should import your test data set in the same manner that you imported your training dataset. First, copy and paste the directory to your test set, then determine the size of your test images and the number of patches you like to generate per image. "
      ],
      "metadata": {
        "id": "P1FQiE1TxhCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Directory to the test set { form-width: \"50%\" }\n",
        "test_image_dr = \"/content/drive/My Drive/data/Fast_STED_Confocal_vs_STED/STED\" #@param {type:\"string\"}\n",
        "test_image_size = 1024 #@param {type:\"integer\"}\n",
        "test_patch_size = 128 #@param {type:\"integer\"}\n",
        "test_n_patches_per_image =  64#@param {type:\"integer\"}\n",
        "test_image_list = os.listdir(image_dr+\"/Average\")\n",
        "print('The image file names are:', *image_list,sep='\\n')\n",
        "Ms = len(image_list)\n",
        "test_GT = np.empty((Ms,test_image_size,test_image_size,1),dtype=np.float32)\n",
        "test_low = np.empty((Ms,test_image_size,test_image_size,1),dtype=np.float32)\n",
        "\n",
        "for i in range(M):\n",
        "  img_GT = load_img(test_image_dr + \"/Average/\"+image_list[i], color_mode=\"grayscale\")\n",
        "  img_low = load_img(test_image_dr + \"/1frame/\"+image_list[i], color_mode=\"grayscale\")\n",
        "\n",
        "  test_GT[i] = img_to_array(img_GT).astype(np.float32)\n",
        "  test_low[i] = img_to_array(img_low).astype(np.float32)\n",
        "\n",
        "\n",
        "test_n_patches_per_row   = np.sqrt(test_n_patches_per_image)\n",
        "test_n_patches_per_row = int(test_n_patches_per_row)\n",
        "\n",
        "test_rr = np.floor(np.linspace(0,test_image_size-test_patch_size-1,test_n_patches_per_row))\n",
        "test_rr.astype(int)\n",
        "test_cc = test_rr\n",
        "\n",
        "test_xx = np.empty((Ms*test_n_patches_per_image,test_patch_size,test_patch_size,1),dtype=np.float32)\n",
        "test_yy = np.empty((Ms*test_n_patches_per_image,test_patch_size,test_patch_size,1),dtype=np.float32)\n",
        "\n",
        "test_count = 0\n",
        "for i in range(Ms):\n",
        "  for j in range(test_n_patches_per_row):\n",
        "    for k in range(test_n_patches_per_row):\n",
        "      test_xx[test_count] = test_low[i,j:j+test_patch_size,k:k+test_patch_size,:]\n",
        "      test_xx[test_count] = test_xx[test_count]/test_xx[test_count].max()\n",
        "      test_yy[test_count] = test_GT[i,j:j+test_patch_size,k:k+test_patch_size,:]\n",
        "      test_yy[test_count] = test_yy[test_count]/test_yy[test_count].max()\n",
        "      test_count+=1\n",
        "\n",
        "print('The test set shape is:',test_xx.shape)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GDZwEW_D7VZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cell #9**\n",
        "\n",
        "In this cell, you are able to import the model that you just trained and test it on your imported test-set. To do so, simply copy and paste the directory to your saved model and run the cell. "
      ],
      "metadata": {
        "id": "8HsV2Tcw-B-T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Vb3wVtdE2oB",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Test a trained model on a test set { form-width: \"50%\" }\n",
        "model_directory = \"/content/drive/My Drive/model-GAN.h5\" #@param {type:\"string\"}\n",
        "\n",
        "def make_generator(inputs,num_filters=num_filters,num_layers=num_layers,kernel_shape=(3,3),dropout=0.4):\n",
        "  filters = []\n",
        "  skip_x = []\n",
        "  for i in range(num_layers):\n",
        "    filters.append((2**i)*num_filters)\n",
        "  y = Conv2D(num_filters,kernel_shape, padding = 'same')(inputs)\n",
        "  y = LeakyReLU()(y)\n",
        "  x = y\n",
        "  for f in filters:\n",
        "    x = res_conv_block(x, f,kernel_shape)\n",
        "    skip_x.append(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Dropout(dropout)(x,training=False)\n",
        "    x = Conv2D(2*f,kernel_shape, padding = 'same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU()(x)\n",
        "\n",
        "  x = res_conv_block(x, 2*filters[-1],kernel_shape)\n",
        "  filters.reverse()\n",
        "  skip_x.reverse()\n",
        "\n",
        "  for i, f in enumerate(filters):\n",
        "    x = Conv2DTranspose(f,kernel_shape, strides = (2, 2), padding = 'same')(x)\n",
        "    xs = skip_x[i]\n",
        "    x = concatenate([x, xs])\n",
        "    x = LeakyReLU()(x)\n",
        "    x = Dropout(dropout)(x,training=False)\n",
        "    x = conv_block(x, f,kernel_shape)\n",
        "\n",
        "  x = Conv2D(num_filters, kernel_shape, padding=\"same\")(x)\n",
        "  x = LeakyReLU()(x)\n",
        "  x = add([x,y])\n",
        "  x = Conv2D(num_filters, kernel_shape, padding=\"same\")(x)\n",
        "  x = LeakyReLU()(x)\n",
        "  x = Conv2D(1, kernel_shape, padding=\"same\")(x)\n",
        "  model = Model(inputs=[inputs], outputs=[x])\n",
        "  return model\n",
        "\n",
        "\n",
        "gan_lr = learning_rate\n",
        "gan_opt = keras.optimizers.Adam(learning_rate=gan_lr)\n",
        "gen_input = Input((test_patch_size,test_patch_size,1))\n",
        "gen_model = make_generator(gen_input,num_filters=num_filters,num_layers=num_layers,kernel_shape=(3,3),dropout=0.3)\n",
        "gen_model.compile(optimizer=gan_opt,loss=percep_loss)\n",
        "\n",
        "\n",
        "gen_model.load_weights(model_save_directory)\n",
        "\n",
        "prediction = np.zeros((test_xx.shape[0],test_xx.shape[1],test_xx.shape[2],1))\n",
        "for i in range(test_xx.shape[0]):\n",
        "  prediction[i] = gen_model.predict(test_xx[i:i+1,:,:,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cell #10**\n",
        "After predictiong your test set, you can plot the output images and compare them with the ground truth here. "
      ],
      "metadata": {
        "id": "6gaT8WV3EDJY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pl6pCBtNFOko",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Plot your prediction results\n",
        "image_number = 10 #@param {type:\"integer\"}\n",
        "#ix = np.random.randint(len(prediction))\n",
        "ix = image_number\n",
        "fig = plt.figure(figsize = (20,15))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(test_xx[ix, :, :, 0] , cmap='magma')\n",
        "plt.axis('off')\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(prediction[ix, :, :, 0] , cmap='magma')\n",
        "plt.axis('off')\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(test_yy[ix, :, :, 0] , cmap='magma')\n",
        "plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cell #11**\n",
        "\n",
        "Finally, it is time to save your test and predicted data set. The images will be transformed to 16 bits and be saved in the same directory as your test data set. "
      ],
      "metadata": {
        "id": "dUnpVCQWEthv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsmkGppEzXTd",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Save your results { form-width: \"50%\" }\n",
        "pred_test = prediction.reshape(prediction.shape[0],test_patch_size,test_patch_size)\n",
        "X_test = test_xx.reshape(test_xx.shape[0],test_patch_size,test_patch_size)\n",
        "Y_test = test_yy.reshape(test_yy.shape[0],test_patch_size,test_patch_size)\n",
        "\n",
        "pred_test = pred_test*(2**16-1)\n",
        "X_test = X_test*(2**16-1)\n",
        "Y_test = Y_test*(2**16-1)\n",
        "\n",
        "pred_test = pred_test.astype(np.uint16)\n",
        "X_test = X_test.astype(np.uint16)\n",
        "Y_test = Y_test.astype(np.uint16)\n",
        "\n",
        "imsave(test_image_dr+'/prediction.tif', pred_test)\n",
        "imsave(test_image_dr+'/x_test.tif', X_test)\n",
        "imsave(test_image_dr+'/y_test.tif', Y_test)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Denoising_GAN.ipynb",
      "provenance": [],
      "mount_file_id": "1VVXbgo_AMQW281-XKbK6ACBHbbzmEpOa",
      "authorship_tag": "ABX9TyMwf2Xbl5cPwFye5NLZgv/s",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}